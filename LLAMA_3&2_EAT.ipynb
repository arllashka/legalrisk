{"cells":[{"cell_type":"markdown","source":["#Setting"],"metadata":{"id":"gPpjY8lNBaP1"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QzSvk9-psdeH"},"outputs":[],"source":["%pip install \"torch==2.2.2\" tensorboard\n","%pip install  --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55274,"status":"ok","timestamp":1717584349588,"user":{"displayName":"Peiling1 Yi","userId":"09881945369780419670"},"user_tz":-60},"id":"N8157Tsw3Vo3","outputId":"e4a45529-8f3c-4079-bee4-3d15c1ed1680"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5NPLc7isjdM"},"outputs":[],"source":["import os\n","import random\n","import functools\n","import csv\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import evaluate\n","from sklearn.metrics import classification_report\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n","\n","from datasets import Dataset, DatasetDict\n","from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n","\n","from transformers import (\n","    AutoModelForSequenceClassification,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorWithPadding\n",")\n"]},{"cell_type":"markdown","source":["#Prepare Emotion data"],"metadata":{"id":"gP6ZTv7zCEe_"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TGxo4CzOHSKT"},"outputs":[],"source":["filepath=\"./data/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qXFnbzq-HOoK"},"outputs":[],"source":["train = pd.read_csv(filepath+\"train.csv\")\n","test = pd.read_csv(filepath+\"test.csv\")\n","go_emotion = pd.read_csv(filepath+\"goemotion.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGELKtfFeKdT"},"outputs":[],"source":["neg_emotion=['gratitude','joy']\n","pos_emotion=['anger','disgust']\n","fake_emotion=['surprise']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQfZPdgjeQAD"},"outputs":[],"source":["def emotion_training_data(Pos_num,Neg_num,Fake_num):\n","  emotions_positive=[]\n","  emotions_negative=[]\n","  emotions_fake=[]\n","  for i in range(len(go_emotion)):\n","    for e in pos_emotion:\n","     if go_emotion.iloc[i][e]==1:\n","        emotions_positive.append(go_emotion.text[i])\n","    for e in neg_emotion:\n","     if go_emotion.iloc[i][e]==1:\n","        emotions_negative.append(go_emotion.text[i])\n","    for e in fake_emotion:\n","     if go_emotion.iloc[i][e]==1:\n","        emotions_fake.append(go_emotion.text[i])\n","  #take away multi-labels from original file\n","  same=[e for e in emotions_negative if e  in emotions_positive or e in emotions_fake]\n","  emotions_negative_new=[e for e in emotions_negative if e not in same]\n","  emotions_positive_new=[e for e in emotions_positive if e not in same]\n","  emotions_fake_new=[e for e in emotions_fake if e not in same]\n","  emotion_contents=emotions_positive_new[:Pos_num]+list(emotions_negative_new[:Neg_num])+list(emotions_fake_new[:Fake_num])\n","  emotions_label=[1]*Pos_num+[0]*Neg_num+[2]*Fake_num\n","  return emotion_contents,emotions_label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q84kIk33edI6"},"outputs":[],"source":["emotion_contents,emotions_label=emotion_training_data(2000,1500,200)\n","train_emotion = pd.DataFrame(emotion_contents)\n","train_emotion['label'] = emotions_label\n","train_emotion_shuffle=train_emotion.sample(frac=1)\n","train_emotion = pd.DataFrame(list(zip(emotion_contents, emotions_label)),\n","               columns =['Comments', 'label'])\n","train_emotion_shuffle=train_emotion.sample(frac=1)\n","train_emotion_shuffle.head()"]},{"cell_type":"markdown","source":["#Define main function"],"metadata":{"id":"eHjGXgDnLSD9"}},{"cell_type":"code","source":["def get_performance_metrics(df_test):\n","  y_test = df_test.label\n","  y_pred = df_test.predictions\n","\n","  print(\"Confusion Matrix:\")\n","  print(confusion_matrix(y_test, y_pred))\n","\n","  print(\"\\nClassification Report:\")\n","  print(classification_report(y_test, y_pred))\n","\n","  print(\"Balanced Accuracy Score:\", balanced_accuracy_score(y_test, y_pred))\n","  print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n","\n","def llama_preprocessing_function(examples):\n","    return tokenizer(examples['Comments'], truncation=True, max_length=MAX_LEN)"],"metadata":{"id":"SgGB38dsGvtF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define which metrics to compute for evaluation\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}"],"metadata":{"id":"Z23zbCOFLaWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define custom trainer\n","class CustomTrainer(Trainer):\n","    def __init__(self, *args, class_weights=None, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        # Ensure label_weights is a tensor\n","        if class_weights is not None:\n","            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n","        else:\n","            self.class_weights = None\n","\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        # Extract labels and convert them to long type for cross_entropy\n","        labels = inputs.pop(\"labels\").long()\n","\n","        # Forward pass\n","        outputs = model(**inputs)\n","\n","        # Extract logits assuming they are directly outputted by the model\n","        logits = outputs.get('logits')\n","\n","        # Compute custom loss with class weights for imbalanced data handling\n","        if self.class_weights is not None:\n","            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n","        else:\n","            loss = F.cross_entropy(logits, labels)\n","\n","        return (loss, outputs) if return_outputs else loss\n","\n","def make_predictions(model,df_test):\n","\n","\n","  # Convert summaries to a list\n","  sentences = df_test.Comments.tolist()\n","\n","  # Define the batch size\n","  batch_size = 32  # You can adjust this based on your system's memory capacity\n","\n","  # Initialize an empty list to store the model outputs\n","  all_outputs = []\n","\n","  # Process the sentences in batches\n","  for i in range(0, len(sentences), batch_size):\n","      # Get the batch of sentences\n","      batch_sentences = sentences[i:i + batch_size]\n","\n","      # Tokenize the batch\n","      inputs = tokenizer(batch_sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n","\n","      # Move tensors to the device where the model is (e.g., GPU or CPU)\n","      inputs = {k: v.to('cuda' if torch.cuda.is_available() else 'cpu') for k, v in inputs.items()}\n","\n","      # Perform inference and store the logits\n","      with torch.no_grad():\n","          outputs = model(**inputs)\n","          all_outputs.append(outputs['logits'])\n","  final_outputs = torch.cat(all_outputs, dim=0)\n","  df_test['predictions']=final_outputs.argmax(axis=1).cpu().numpy()\n","  #df_test['predictions']=df_test['predictions'].apply(lambda l:category_map[l])\n"],"metadata":{"id":"qTagYtGHIiLc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Define Model&Training"],"metadata":{"id":"QPxb783vT2am"}},{"cell_type":"code","source":["#model_name = \"meta-llama/Meta-Llama-3-8B\"\n","model_name= \"meta-llama/Llama-2-7b-hf\""],"metadata":{"id":"GZXRaycHEf-P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def define_model(model_name):\n","  quantization_config = BitsAndBytesConfig(\n","    load_in_4bit = True, # enable 4-bit quantization\n","    bnb_4bit_quant_type = 'nf4', # information theoretically optimal dtype for normally distributed weights\n","    bnb_4bit_use_double_quant = True, # quantize quantized weights //insert xzibit meme\n","    bnb_4bit_compute_dtype = torch.bfloat16 # optimized fp format for ML\n","  )\n","  lora_config = LoraConfig(\n","    r = 16, # the dimension of the low-rank matrices\n","    lora_alpha = 8, # scaling factor for LoRA activations vs pre-trained weight activations\n","    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n","    lora_dropout = 0.05, # dropout probability of the LoRA layers\n","    bias = 'none', # wether to train bias weights, set to 'none' for attention layers\n","    task_type = 'SEQ_CLS'\n","  )\n","  model = AutoModelForSequenceClassification.from_pretrained(\n","    model_name,\n","    quantization_config=quantization_config,\n","    num_labels=3\n","  )\n","  #prepare_model_for_kbit_training() function to preprocess the quantized model for training.\n","  model = prepare_model_for_kbit_training(model)\n","  #get_peft_model prepares a model for training with a PEFT method such as LoRA by wrapping the base model and PEFT configuration with\n","  model = get_peft_model(model, lora_config)\n","\n","  #Load tokennizer\n","  tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n","  tokenizer.pad_token_id = tokenizer.eos_token_id\n","  tokenizer.pad_token = tokenizer.eos_token\n","\n","  #Update some model configs\n","  model.config.pad_token_id = tokenizer.pad_token_id\n","  model.config.use_cache = False\n","  model.config.pretraining_tp = 1\n","\n","  MAX_LEN = 512\n","  training_args = TrainingArguments(\n","    output_dir = 'emotion_cyberbullying',\n","    learning_rate = 1e-4,\n","    per_device_train_batch_size = 8,\n","    per_device_eval_batch_size = 8,\n","    num_train_epochs = 2,\n","    weight_decay = 0.01,\n","    evaluation_strategy = 'epoch',\n","    save_strategy = 'epoch',\n","    load_best_model_at_end = True)\n","  return model, tokenizer, training_args"],"metadata":{"id":"gQQlW04-FC7l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def training(dataset,train_class,model,tokenizer,training_args):\n","  class_weights=(1/train_class.label.value_counts(normalize=True).sort_index()).tolist()\n","  class_weights=torch.tensor(class_weights)\n","  class_weights=class_weights/class_weights.sum()\n","\n","  tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True)\n","  tokenized_datasets.set_format(\"torch\")\n","  collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","  trainer = CustomTrainer(\n","      model = model,\n","      args = training_args,\n","      train_dataset = tokenized_datasets['train'],\n","      eval_dataset = tokenized_datasets['val'],\n","      tokenizer = tokenizer,\n","      data_collator = collate_fn,\n","      compute_metrics = compute_metrics,\n","      class_weights=class_weights,\n","  )\n","  train_result = trainer.train()\n","\n","  return model, trainer,train_result\n"],"metadata":{"id":"fCjEjyp8ggOL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Baseline"],"metadata":{"id":"1dvEJb-IGaol"}},{"cell_type":"code","source":["df_train=train\n","df_value=train\n","df_test=test\n","\n","dataset_train = Dataset.from_pandas(train)\n","dataset_val = Dataset.from_pandas(train[:10])\n","dataset_test = Dataset.from_pandas(test)\n","\n","dataset = DatasetDict({\n","    'train': dataset_train,\n","    'val': dataset_val,\n","    'test': dataset_test\n","  })\n","\n","model_new,tokenizer_new, training_args_new=define_model(model_name)\n","model_train,trainer,_=training(dataset,df_train,model_new,tokenizer_new, training_args_new)\n","make_predictions(model_train,df_test)\n","get_performance_metrics(df_test)"],"metadata":{"id":"4SyobsNGGgNa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ZCS"],"metadata":{"id":"GbrNbmTqMPGs"}},{"cell_type":"code","source":["\n","df_train=train_emotion_shuffle\n","df_value=train_emotion_shuffle[:10]\n","df_test=test\n","\n","dataset_train = Dataset.from_pandas(train_emotion_shuffle)\n","dataset_val = Dataset.from_pandas(train_emotion_shuffle[:10])\n","dataset_test = Dataset.from_pandas(test)\n","\n","dataset = DatasetDict({\n","    'train': dataset_train,\n","    'val': dataset_val,\n","    'test': dataset_test\n","  })\n","\n","model_new,tokenizer_new, training_args_new=define_model(model_name)\n","model_train_zsc,trainer,_=training(dataset,df_train,model_new,tokenizer_new, training_args_new)\n","make_predictions(model=model_train_zsc,df_test=df_test)\n","get_performance_metrics(df_test)"],"metadata":{"id":"BMjuCMcrMVi5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#FSC-based on ZSC for fine tunning"],"metadata":{"id":"oFjVXGG9G1cZ"}},{"cell_type":"code","source":["df_train=train\n","df_value=train\n","df_test=test\n","\n","dataset_train = Dataset.from_pandas(train)\n","dataset_val = Dataset.from_pandas(train[:10])\n","dataset_test = Dataset.from_pandas(test)\n","\n","\n","dataset = DatasetDict({\n","    'train': dataset_train,\n","    'val': dataset_val,\n","    'test': dataset_test\n","  })\n","\n","model_train_FCS,trainer_FCS,_=training(dataset=dataset,train_class=df_train,model=model_train_zsc,tokenizer=tokenizer_new,training_args=training_args_new)\n","make_predictions(model=model_train_FCS,df_test=df_test)\n","get_performance_metrics(df_test)"],"metadata":{"id":"2LoJC45_yyq8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eZTHqTuPir_k"},"source":["## Saving the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KnCfi0Z3W567"},"outputs":[],"source":["metrics = train_result.metrics\n","max_train_samples = len(dataset_train)\n","metrics[\"train_samples\"] = min(max_train_samples, len(dataset_train))\n","trainer.log_metrics(\"train\", metrics)\n","trainer.save_metrics(\"train\", metrics)\n","trainer.save_state()\n","trainer.save_model(\"saved_model\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}