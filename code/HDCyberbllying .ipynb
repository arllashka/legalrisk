{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "HRyfIxtiXtl-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0                                           Comments  label\n",
       " 0         815  \"\\n\\nWP:BURDEN is with you. '''''' Dick Lauren...      1\n",
       " 1        1618  It is important as it was by the means of this...      0\n",
       " 2        2828  https://www.vanityfair.com/style/2017/09/jim-c...      0\n",
       " 3        1559  =- Jacob Barnett\\n                            ...      0\n",
       " 4         836  \"  And I never got a chance to \"\"State my Case...      1,\n",
       " Index(['Unnamed: 0', 'Comments', 'label'], dtype='object'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_path = \"/Users/arlankalin/Downloads/Cyberbullying-emotion-main/data/train.csv\"\n",
    "train_df = pd.read_csv(train_path)\n",
    "\n",
    "# Inspect column names and unique values in label column\n",
    "train_df.head(), train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0                                           Comments  label\n",
       " 0        2300  \"\\n\\nI just wonder how  can say one day  \"\"I c...      0\n",
       " 1        1243  Al Messier \\nThis article was a non-notable bi...      0\n",
       " 2         943          You and Jack greenmaven are MotherFuckers      1\n",
       " 3        2606  Retiring Soon? Kanye West Is Stepping Away Fro...      2\n",
       " 4        2411  Heartbroken Jennifer Aniston Runs For The Bord...      2,\n",
       " Index(['Unnamed: 0', 'Comments', 'label'], dtype='object'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = \"/Users/arlankalin/Downloads/Cyberbullying-emotion-main/data/test.csv\"\n",
    "test_df = pd.read_csv(test_path)\n",
    "\n",
    "# Inspect column names and unique values in label column\n",
    "test_df.head(), test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    1301\n",
      "1    1085\n",
      "2     229\n",
      "Name: count, dtype: int64\n",
      "(2615, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_df['label'].value_counts())\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IkWx5HhdjKAD"
   },
   "outputs": [],
   "source": [
    "DATANUMBER=2000\n",
    "MINLENGTH=15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlTK1-A0fUWO"
   },
   "source": [
    "##Prepare Harassement samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qmE5NruuQw7Z"
   },
   "outputs": [],
   "source": [
    "#Download from https://www.kaggle.com/datasets/surekharamireddy/malignant-comment-classification, only train.csv. Change name to harassement_reviews\n",
    "\n",
    "harassment_reviews = pd.read_csv(\"/Users/arlankalin/Downloads/Cyberbullying-emotion-main/data/harassment_reviews.csv\", index_col=0) #Cyberbullying datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1ej6y1sMX1u3"
   },
   "outputs": [],
   "source": [
    "label=[]\n",
    "tags=['malignant','highly_malignant','rude','threat','abuse','loathe'] #original tags, merge to one\n",
    "for i in range(len(harassment_reviews)):\n",
    "  if (harassment_reviews.iloc[i]['malignant']+harassment_reviews.iloc[i]['highly_malignant']+harassment_reviews.iloc[i]['rude']+harassment_reviews.iloc[i]['threat']+harassment_reviews.iloc[i]['abuse']+harassment_reviews.iloc[i]['loathe'])>=1:\n",
    "    label.append(1)\n",
    "  else:\n",
    "    label.append(0)\n",
    "harassment_reviews['label']=label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OgfFqL_URT-R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-27 23:17:19--  https://nlp.stanford.edu/software/stanford-ner-4.2.0.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-ner-4.2.0.zip [following]\n",
      "--2025-07-27 23:17:19--  https://downloads.cs.stanford.edu/nlp/software/stanford-ner-4.2.0.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 180437064 (172M) [application/zip]\n",
      "Saving to: ‘stanford-ner-4.2.0.zip’\n",
      "\n",
      "stanford-ner-4.2.0. 100%[===================>] 172,08M  5,00MB/s    in 36s     \n",
      "\n",
      "2025-07-27 23:17:56 (4,75 MB/s) - ‘stanford-ner-4.2.0.zip’ saved [180437064/180437064]\n",
      "\n",
      "Archive:  stanford-ner-4.2.0.zip\n",
      "   creating: stanford-ner-2020-11-17/\n",
      "   creating: stanford-ner-2020-11-17/lib/\n",
      "  inflating: stanford-ner-2020-11-17/lib/jollyday-0.4.9.jar  \n",
      "  inflating: stanford-ner-2020-11-17/lib/stanford-ner-resources.jar  \n",
      "  inflating: stanford-ner-2020-11-17/lib/joda-time.jar  \n",
      "  inflating: stanford-ner-2020-11-17/stanford-ner-4.2.0.jar  \n",
      "  inflating: stanford-ner-2020-11-17/NERDemo.java  \n",
      "  inflating: stanford-ner-2020-11-17/LICENSE.txt  \n",
      "  inflating: stanford-ner-2020-11-17/sample-conll-file.txt  \n",
      "  inflating: stanford-ner-2020-11-17/stanford-ner-4.2.0-javadoc.jar  \n",
      "  inflating: stanford-ner-2020-11-17/stanford-ner-4.2.0-sources.jar  \n",
      "  inflating: stanford-ner-2020-11-17/stanford-ner.jar  \n",
      "  inflating: stanford-ner-2020-11-17/sample.txt  \n",
      "  inflating: stanford-ner-2020-11-17/build.xml  \n",
      "  inflating: stanford-ner-2020-11-17/ner-gui.bat  \n",
      "  inflating: stanford-ner-2020-11-17/sample-w-time.txt  \n",
      "  inflating: stanford-ner-2020-11-17/ner-gui.command  \n",
      "   creating: stanford-ner-2020-11-17/classifiers/\n",
      "  inflating: stanford-ner-2020-11-17/classifiers/english.muc.7class.distsim.prop  \n",
      "  inflating: stanford-ner-2020-11-17/classifiers/english.all.3class.distsim.crf.ser.gz  \n",
      "  inflating: stanford-ner-2020-11-17/classifiers/english.conll.4class.distsim.crf.ser.gz  \n",
      "  inflating: stanford-ner-2020-11-17/classifiers/example.serialized.ncc.prop  \n",
      "  inflating: stanford-ner-2020-11-17/classifiers/english.muc.7class.distsim.crf.ser.gz  \n",
      "  inflating: stanford-ner-2020-11-17/classifiers/english.all.3class.distsim.prop  \n",
      "  inflating: stanford-ner-2020-11-17/classifiers/example.serialized.ncc.ncc.ser.gz  \n",
      "  inflating: stanford-ner-2020-11-17/classifiers/english.conll.4class.distsim.prop  \n",
      "  inflating: stanford-ner-2020-11-17/ner-gui.sh  \n",
      "  inflating: stanford-ner-2020-11-17/sample.ner.txt  \n",
      "  inflating: stanford-ner-2020-11-17/ner.bat  \n",
      "  inflating: stanford-ner-2020-11-17/README.txt  \n",
      "  inflating: stanford-ner-2020-11-17/ner.sh  \n"
     ]
    }
   ],
   "source": [
    "#Tag name on the comments\n",
    "!wget 'https://nlp.stanford.edu/software/stanford-ner-4.2.0.zip'\n",
    "!unzip stanford-ner-4.2.0.zip\n",
    "PATH_TO_JAR='/Users/arlankalin/Downloads/Cyberbullying-emotion-main/stanford-ner-2020-11-17/stanford-ner-4.2.0.jar'\n",
    "PATH_TO_MODEL = '/Users/arlankalin/Downloads/Cyberbullying-emotion-main/stanford-ner-2020-11-17/classifiers/english.all.3class.distsim.crf.ser.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Java/JavaVirtualMachines/temurin-17.jdk/Contents/Home/bin/java\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"JAVAHOME\"] = \"/Library/Java/JavaVirtualMachines/temurin-17.jdk/Contents/Home/bin/java\"\n",
    "# ni.find_java()          # populates ni._java_bin\n",
    "# print(\"Java NLTK will use →\", ni._java_bin)\n",
    "print(os.environ.get(\"JAVAHOME\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in /opt/miniconda3/envs/cb/lib/python3.13/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/cb/lib/python3.13/site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/miniconda3/envs/cb/lib/python3.13/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/envs/cb/lib/python3.13/site-packages (from nltk) (4.67.1)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVAHOME\"] = \"/Library/Java/JavaVirtualMachines/jdk-21.jdk/Contents/Home/bin/java\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Java/JavaVirtualMachines/jdk-21.jdk/Contents/Home/bin/java\n"
     ]
    }
   ],
   "source": [
    "import nltk.internals as ni\n",
    "os.environ[\"JAVAHOME\"] = \"/Library/Java/JavaVirtualMachines/jdk-21.jdk/Contents/Home/bin/java\"\n",
    "ni._java_bin = None  \n",
    "ni.config_java()  \n",
    "print(ni._java_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Barack', 'PERSON'), ('Obama', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "PATH_TO_MODEL = \"/Users/arlankalin/Downloads/Cyberbullying-emotion-main/stanford-ner-2020-11-17/classifiers/english.all.3class.distsim.crf.ser.gz\"\n",
    "PATH_TO_JAR   = \"/Users/arlankalin/Downloads/Cyberbullying-emotion-main/stanford-ner-2020-11-17/stanford-ner-4.2.0.jar\"\n",
    "\n",
    "st = StanfordNERTagger(model_filename=PATH_TO_MODEL, path_to_jar=PATH_TO_JAR)\n",
    "print(st.tag([\"Barack\", \"Obama\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571\n",
      "0\n",
      "0 0\n",
      "1\n",
      "0 0\n",
      "2\n",
      "0 0\n",
      "3\n",
      "0 0\n",
      "4\n",
      "0 0\n",
      "5\n",
      "0 0\n",
      "6\n",
      "0 0\n",
      "7\n",
      "0 1\n",
      "8\n",
      "0 1\n",
      "9\n",
      "0 1\n",
      "10\n",
      "0 1\n",
      "11\n",
      "0 1\n",
      "12\n",
      "1 1\n",
      "13\n",
      "1 1\n",
      "14\n",
      "1 1\n",
      "15\n",
      "1 2\n",
      "16\n",
      "2 2\n",
      "17\n",
      "2 3\n",
      "18\n",
      "2 4\n",
      "19\n",
      "2 4\n",
      "20\n",
      "2 4\n",
      "21\n",
      "2 5\n",
      "22\n",
      "2 6\n",
      "23\n",
      "2 6\n",
      "24\n",
      "2 7\n",
      "25\n",
      "2 8\n",
      "26\n",
      "2 8\n",
      "27\n",
      "2 9\n",
      "28\n",
      "2 9\n",
      "29\n",
      "2 9\n",
      "30\n",
      "2 9\n",
      "31\n",
      "2 9\n",
      "32\n",
      "2 9\n",
      "33\n",
      "2 9\n",
      "34\n",
      "2 9\n",
      "35\n",
      "2 10\n",
      "36\n",
      "2 10\n",
      "37\n",
      "2 10\n",
      "38\n",
      "2 10\n",
      "39\n",
      "2 10\n",
      "40\n",
      "2 10\n",
      "41\n",
      "2 10\n",
      "42\n",
      "2 10\n",
      "43\n",
      "2 10\n",
      "44\n",
      "2 10\n",
      "45\n",
      "2 10\n",
      "46\n",
      "2 10\n",
      "47\n",
      "2 10\n",
      "48\n",
      "2 10\n",
      "49\n",
      "2 11\n",
      "50\n",
      "2 11\n",
      "51\n",
      "2 11\n",
      "52\n",
      "2 11\n",
      "53\n",
      "2 11\n",
      "54\n",
      "2 11\n",
      "55\n",
      "2 11\n",
      "56\n",
      "3 11\n",
      "57\n",
      "3 11\n",
      "58\n",
      "3 11\n",
      "59\n",
      "4 11\n",
      "60\n",
      "4 11\n",
      "61\n",
      "4 11\n",
      "62\n",
      "4 12\n",
      "63\n",
      "4 12\n",
      "64\n",
      "4 13\n",
      "65\n",
      "4 13\n",
      "66\n",
      "4 13\n",
      "67\n",
      "4 13\n",
      "68\n",
      "4 13\n",
      "69\n",
      "4 13\n",
      "70\n",
      "4 13\n",
      "71\n",
      "4 13\n",
      "72\n",
      "4 13\n",
      "73\n",
      "4 13\n",
      "74\n",
      "4 13\n",
      "75\n",
      "4 13\n",
      "76\n",
      "4 13\n",
      "77\n",
      "4 13\n",
      "78\n",
      "4 13\n",
      "79\n",
      "4 13\n",
      "80\n",
      "4 13\n",
      "81\n",
      "4 14\n",
      "82\n",
      "4 14\n",
      "83\n",
      "4 15\n",
      "84\n",
      "4 15\n",
      "85\n",
      "4 15\n",
      "86\n",
      "4 15\n",
      "87\n",
      "4 15\n",
      "88\n",
      "4 15\n",
      "89\n",
      "4 15\n",
      "90\n",
      "4 15\n",
      "91\n",
      "4 15\n",
      "92\n",
      "4 15\n",
      "93\n",
      "4 15\n",
      "94\n",
      "4 15\n",
      "95\n",
      "4 16\n",
      "96\n",
      "4 16\n",
      "97\n",
      "4 16\n",
      "98\n",
      "4 16\n",
      "99\n",
      "4 16\n",
      "100\n",
      "4 16\n",
      "101\n",
      "4 16\n",
      "102\n",
      "4 16\n",
      "103\n",
      "4 16\n",
      "104\n",
      "4 17\n",
      "105\n",
      "4 17\n",
      "106\n",
      "4 17\n",
      "107\n",
      "4 18\n",
      "108\n",
      "4 18\n",
      "109\n",
      "4 18\n",
      "110\n",
      "4 19\n",
      "111\n",
      "4 19\n",
      "112\n",
      "4 19\n",
      "113\n",
      "4 20\n",
      "114\n",
      "4 20\n",
      "115\n",
      "4 20\n",
      "116\n",
      "4 20\n",
      "117\n",
      "4 21\n",
      "118\n",
      "4 21\n",
      "119\n",
      "4 21\n",
      "120\n",
      "4 21\n",
      "121\n",
      "4 21\n",
      "122\n",
      "4 21\n",
      "123\n",
      "4 21\n",
      "124\n",
      "4 21\n",
      "125\n",
      "4 21\n",
      "126\n",
      "4 22\n",
      "127\n",
      "4 22\n",
      "128\n",
      "4 22\n",
      "129\n",
      "4 23\n",
      "130\n",
      "4 23\n",
      "131\n",
      "4 23\n",
      "132\n",
      "4 23\n",
      "133\n",
      "4 23\n",
      "134\n",
      "4 23\n",
      "135\n",
      "4 23\n",
      "136\n",
      "4 24\n",
      "137\n",
      "4 24\n",
      "138\n",
      "4 24\n",
      "139\n",
      "4 24\n",
      "140\n",
      "4 24\n",
      "141\n",
      "4 24\n",
      "142\n",
      "4 24\n",
      "143\n",
      "4 25\n",
      "144\n",
      "4 26\n",
      "145\n",
      "4 26\n",
      "146\n",
      "4 27\n",
      "147\n",
      "4 27\n",
      "148\n",
      "4 28\n",
      "149\n",
      "4 29\n",
      "150\n",
      "4 30\n",
      "151\n",
      "5 30\n",
      "152\n",
      "5 30\n",
      "153\n",
      "5 30\n",
      "154\n",
      "5 30\n",
      "155\n",
      "5 30\n",
      "156\n",
      "5 30\n",
      "157\n",
      "5 30\n",
      "158\n",
      "5 30\n",
      "159\n",
      "5 30\n",
      "160\n",
      "5 31\n",
      "161\n",
      "5 31\n",
      "162\n",
      "5 32\n",
      "163\n",
      "5 32\n",
      "164\n",
      "5 32\n",
      "165\n",
      "5 32\n",
      "166\n",
      "5 33\n",
      "167\n",
      "5 33\n",
      "168\n",
      "5 33\n",
      "169\n",
      "5 33\n",
      "170\n",
      "5 33\n",
      "171\n",
      "5 33\n",
      "172\n",
      "5 33\n",
      "173\n",
      "5 33\n",
      "174\n",
      "5 34\n",
      "175\n",
      "5 34\n",
      "176\n",
      "5 34\n",
      "177\n",
      "5 34\n",
      "178\n",
      "5 34\n",
      "179\n",
      "5 34\n",
      "180\n",
      "5 35\n",
      "181\n",
      "5 35\n",
      "182\n",
      "5 36\n",
      "183\n",
      "5 36\n",
      "184\n",
      "5 36\n",
      "185\n",
      "5 37\n",
      "186\n",
      "5 37\n",
      "187\n",
      "5 37\n",
      "188\n",
      "5 38\n",
      "189\n",
      "5 38\n",
      "190\n",
      "5 38\n",
      "191\n",
      "5 38\n",
      "192\n",
      "5 38\n",
      "193\n",
      "5 39\n",
      "194\n",
      "5 39\n",
      "195\n",
      "5 39\n",
      "196\n",
      "5 39\n",
      "197\n",
      "5 39\n",
      "198\n",
      "5 39\n",
      "199\n",
      "5 40\n",
      "200\n",
      "5 40\n",
      "201\n",
      "5 40\n",
      "202\n",
      "5 40\n",
      "203\n",
      "5 40\n",
      "204\n",
      "5 40\n",
      "205\n",
      "5 40\n",
      "206\n",
      "5 40\n",
      "207\n",
      "5 41\n",
      "208\n",
      "5 41\n",
      "209\n",
      "5 41\n",
      "210\n",
      "5 41\n",
      "211\n",
      "5 41\n",
      "212\n",
      "5 41\n",
      "213\n",
      "5 41\n",
      "214\n",
      "5 42\n",
      "215\n",
      "5 42\n",
      "216\n",
      "5 42\n",
      "217\n",
      "5 42\n",
      "218\n",
      "5 42\n",
      "219\n",
      "5 42\n",
      "220\n",
      "5 42\n",
      "221\n",
      "5 42\n",
      "222\n",
      "5 42\n",
      "223\n",
      "5 42\n",
      "224\n",
      "5 42\n",
      "225\n",
      "5 42\n",
      "226\n",
      "5 42\n",
      "227\n",
      "5 42\n",
      "228\n",
      "5 42\n",
      "229\n",
      "5 42\n",
      "230\n",
      "5 43\n",
      "231\n",
      "6 43\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "DATANUMBER=5\n",
    "PATH_TO_JAR='/Users/arlankalin/Downloads/Cyberbullying-emotion-main/stanford-ner-2020-11-17/stanford-ner-4.2.0.jar'\n",
    "PATH_TO_MODEL = '/Users/arlankalin/Downloads/Cyberbullying-emotion-main/stanford-ner-2020-11-17/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "from nltk.tag.stanford import StanfordNERTagger\n",
    "collectdata_pos_index=[]\n",
    "collectdata_neg_index=[]\n",
    "name_pos=[]\n",
    "name_neg=[]\n",
    "print(len(harassment_reviews))\n",
    "st=StanfordNERTagger(model_filename=PATH_TO_MODEL, path_to_jar=PATH_TO_JAR, encoding='utf-8')\n",
    "for i in range(len(harassment_reviews)):\n",
    "  print(i)\n",
    "  sentence=harassment_reviews['comment_text'].iloc[i]\n",
    "  tokens = re.findall('\\\\b[A-Z][A-Za-z]+\\\\b',sentence)\n",
    "  tags = st.tag(tokens)\n",
    "  for tag in tags:\n",
    "      if tag[1]=='PERSON':\n",
    "        if harassment_reviews['label'].iloc[i] == 1:\n",
    "            collectdata_pos_index.append(i)\n",
    "            name_pos.append(tag[0])\n",
    "        else:\n",
    "          collectdata_neg_index.append(i)\n",
    "          name_neg.append(tag[0])\n",
    "        break\n",
    "  print(len(collectdata_pos_index), len(collectdata_neg_index))\n",
    "  if len(collectdata_pos_index)>DATANUMBER and len(collectdata_neg_index)>DATANUMBER : break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9NLIm6JfNGf"
   },
   "source": [
    "##Prepare Fake&legit samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bhXtjKStQ77L"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/arlankalin/Downloads/Cyberbullying-emotion-main/fake/001fake.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m,\u001b[32m250\u001b[39m):\n\u001b[32m      5\u001b[39m   filename=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[33m\"\u001b[39m.format(i)+\u001b[33m\"\u001b[39m\u001b[33mfake.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m   file = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfake/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m+\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m   fake.append(file.read())\n\u001b[32m      8\u001b[39m   file.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/cb/lib/python3.13/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/arlankalin/Downloads/Cyberbullying-emotion-main/fake/001fake.txt'"
     ]
    }
   ],
   "source": [
    "#fake sample\n",
    "fake=[]\n",
    "for i in range(1,250):\n",
    "  filename=\"{:03d}\".format(i)+\"fake.txt\"\n",
    "  file = open(filepath+\"fake/\"+filename, \"r\")\n",
    "  fake.append(file.read())\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yakt5OQcQ9e7"
   },
   "outputs": [],
   "source": [
    "#legit sample\n",
    "legit=[]\n",
    "for i in range(1,250):\n",
    "  filename=\"{:03d}\".format(i)+\"legit.txt\"\n",
    "  file = open(filepath+\"legit/\"+filename, \"r\")\n",
    "  legit.append(file.read())\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nb1S-Wh8p9dg"
   },
   "source": [
    "##Create HDCyberbullying dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzVRXj95p9Y3"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DqGHLJNEG3nI"
   },
   "outputs": [],
   "source": [
    "pos_comment=[]\n",
    "for i in collectdata_pos_index:\n",
    " if len(harassment_reviews.iloc[i].comment_text)>MINLENGTH:\n",
    "    pos_comment.append(harassment_reviews.iloc[i].comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Av7wu920G3nI"
   },
   "outputs": [],
   "source": [
    "neg_comment=[]\n",
    "for i in collectdata_neg_index:\n",
    " if len(harassment_reviews.iloc[i].comment_text)>MINLENGTH:\n",
    "    neg_comment.append(harassment_reviews.iloc[i].comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "MyRJZmCZpSyv"
   },
   "outputs": [],
   "source": [
    "data=[]\n",
    "for p in pos_comment:\n",
    "  data.append([p,1])\n",
    "for n in neg_comment:\n",
    "  data.append([n,0])\n",
    "# for f in fake:\n",
    "#   data.append([f,2])\n",
    "# for l in legit:\n",
    "#   data.append([l,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "SPIcGBGdpgt4"
   },
   "outputs": [],
   "source": [
    "header = ['Comments', 'label']\n",
    "HDCyberbullying = pd.DataFrame(data, columns=header)\n",
    "train, test = train_test_split(HDCyberbullying, test_size=0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP8gcCd5yYTeJkCXS/LrWdi",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "cb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
